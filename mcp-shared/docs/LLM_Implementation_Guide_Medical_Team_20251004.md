# åŒ»ç™‚ãƒãƒ¼ãƒ å‘ã‘ LLM APIå®Ÿè£…ã‚¬ã‚¤ãƒ‰ - VoiceDrive MockLLMæº–æ‹ ç‰ˆ

**æ–‡æ›¸ç•ªå·**: IMPL-GUIDE-2025-1004-006
**ä½œæˆæ—¥**: 2025å¹´10æœˆ4æ—¥
**ä½œæˆè€…**: åŒ»ç™‚è·å“¡ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãƒãƒ¼ãƒ 
**å‚ç…§å…ƒ**: VoiceDriveãƒãƒ¼ãƒ  MockLLMAPIServerå®Ÿè£…
**å¯¾è±¡èª­è€…**: åŒ»ç™‚ãƒãƒ¼ãƒ LLMã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ»APIé–‹ç™ºè€…
**é‡è¦åº¦**: ğŸ”´ æœ€é‡è¦

---

## ğŸ“‹ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

VoiceDriveãƒãƒ¼ãƒ ã®MockLLMã‚µãƒ¼ãƒãƒ¼å®Ÿè£…ã‚’è©³ç´°ã«è§£æã—ã€**åŒ»ç™‚ãƒãƒ¼ãƒ ãŒå®Ÿè£…ã™ã¹ãLlama 3.2 8B API**ã®ä»•æ§˜ã‚’ç¢ºå®šã—ã¾ã—ãŸã€‚

MockLLMå®Ÿè£…ã¯éå¸¸ã«é«˜å“è³ªã§ã‚ã‚Šã€ã“ã‚Œã‚’**å®Ÿè£…ã®ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰**ã¨ã—ã¦ã€åŒ»ç™‚ãƒãƒ¼ãƒ ã¯ä»¥ä¸‹ã‚’é”æˆã—ã¾ã™ï¼š

1. **å‹•ä½œä¸€è²«æ€§**: MockLLMã¨å®ŸLLMã®å¿œç­”ãŒ90%ä»¥ä¸Šä¸€è‡´
2. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: MockLLMï¼ˆ300-800msï¼‰ã‚ˆã‚Šé«˜é€Ÿãª1.5ç§’ä»¥å†…
3. **ç²¾åº¦å‘ä¸Š**: ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢75-95%ã‚’å®‰å®šçš„ã«é”æˆ

æœ¬ã‚¬ã‚¤ãƒ‰ã§ã¯ã€VoiceDrive MockLLMã®å„ªã‚ŒãŸè¨­è¨ˆã‚’è¸è¥²ã—ã¤ã¤ã€Llama 3.2 8Bã®å¼·åŠ›ãªæ–‡è„ˆç†è§£èƒ½åŠ›ã‚’æ´»ç”¨ã™ã‚‹å®Ÿè£…æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚

---

## ç›®æ¬¡

1. [VoiceDrive MockLLMå®Ÿè£…ã®åˆ†æ](#voicedrive-mockllmå®Ÿè£…ã®åˆ†æ)
2. [åŒ»ç™‚ãƒãƒ¼ãƒ å®Ÿè£…ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](#åŒ»ç™‚ãƒãƒ¼ãƒ å®Ÿè£…ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£)
3. [Llama 3.2 8Bãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°](#llama-32-8bãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°)
4. [é•åæ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè£…](#é•åæ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè£…)
5. [ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—](#ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—)
6. [ä¿®æ­£ææ¡ˆç”Ÿæˆ](#ä¿®æ­£ææ¡ˆç”Ÿæˆ)
7. [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–](#ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–)
8. [ãƒ†ã‚¹ãƒˆæˆ¦ç•¥](#ãƒ†ã‚¹ãƒˆæˆ¦ç•¥)
9. [å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ](#å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ)

---

## VoiceDrive MockLLMå®Ÿè£…ã®åˆ†æ

### 1.1 å„ªã‚Œã¦ã„ã‚‹ç‚¹

#### âœ… æ¤œå‡ºãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç¶²ç¾…æ€§

**MockLLMå®Ÿè£…**:
```typescript
private readonly MOCK_PATTERNS = {
  personal_attack: [
    /ãƒã‚«|é¦¬é¹¿|ã‚¢ãƒ›|ç„¡èƒ½|å½¹ç«‹ãŸãš/gi,
    /ä½¿ãˆãªã„|ãƒ€ãƒ¡äººé–“|ã‚¯ã‚º/gi
  ],
  defamation: [
    /æ‚ªå£|ä¸­å‚·|å˜˜ã¤ã|è©æ¬ºå¸«/gi,
    /ä¿¡ç”¨ã§ããªã„|ç–‘ã‚ã—ã„/gi
  ],
  harassment: [
    /ãƒ‘ãƒ¯ãƒãƒ©|ã‚»ã‚¯ãƒãƒ©|ã„ã˜ã‚/gi,
    /è¾ã‚ã‚|ã‚¯ãƒ“|è¿½ã„å‡ºã™/gi
  ],
  // ...
};
```

**å­¦ã³**:
- å„é•åã‚¿ã‚¤ãƒ—ã«è¤‡æ•°ã®æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
- æ—¥æœ¬èªã®å¤šæ§˜ãªè¡¨ç¾ã‚’ç¶²ç¾…
- æ®µéšçš„ãªæ¤œå‡ºï¼ˆè»½å¾®â†’é‡åº¦ï¼‰

**åŒ»ç™‚ãƒãƒ¼ãƒ ã§ã®æ´»ç”¨**:
```python
# ã“ã‚Œã‚‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’Llama 3.2 8Bã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æ´»ç”¨
# Few-shot Learningã®ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆã«åˆ©ç”¨
MOCK_PATTERNS_FOR_TRAINING = {
    'personal_attack': [
        "ã“ã®æŠ•ç¨¿ã«ã¯ã€Œãƒã‚«ã€ã¨ã„ã†å€‹äººæ”»æ’ƒçš„ãªè¡¨ç¾ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ â†’ personal_attack",
        "ã€Œç„¡èƒ½ã€ã¨ã„ã†è¨€è‘‰ã¯ç‰¹å®šå€‹äººã¸ã®æ”»æ’ƒã§ã™ â†’ personal_attack",
        # VoiceDrive MockLLMã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰100ä»¶ç”Ÿæˆ
    ]
}
```

#### âœ… å»ºè¨­æ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—

**MockLLMå®Ÿè£…**:
```typescript
private calculateConstructiveScore(content: string): number {
  let score = 50;

  // ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã‚¹ã‚³ã‚¢ã‚¢ãƒƒãƒ—
  this.CONSTRUCTIVE_PATTERNS.forEach(pattern => {
    const matches = content.match(pattern);
    if (matches) {
      score += matches.length * 10;
    }
  });

  // é•åãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã‚¹ã‚³ã‚¢ãƒ€ã‚¦ãƒ³
  Object.values(this.MOCK_PATTERNS).forEach(patterns => {
    patterns.forEach(pattern => {
      const matches = content.match(pattern);
      if (matches) {
        score -= matches.length * 15;
      }
    });
  });

  return Math.max(0, Math.min(100, score));
}
```

**å­¦ã³**:
- ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢50ã‹ã‚‰åŠ æ¸›ç®—
- ãƒã‚¸ãƒ†ã‚£ãƒ– +10ç‚¹ã€ãƒã‚¬ãƒ†ã‚£ãƒ– -15ç‚¹
- 0-100ã®ç¯„å›²ã§æ­£è¦åŒ–

**åŒ»ç™‚ãƒãƒ¼ãƒ ã§ã®æ´»ç”¨**:
```python
# Llama 3.2 8Bã§ã®å®Ÿè£…
def calculate_constructive_score_llm(content: str) -> int:
    """
    LLMã‚’ä½¿ã£ãŸé«˜åº¦ãªå»ºè¨­æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
    MockLLMã®å˜ç´”ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã‚ˆã‚Šç²¾åº¦å‘ä¸Š
    """
    prompt = f"""
ä»¥ä¸‹ã®æŠ•ç¨¿ã®å»ºè¨­æ€§ã‚¹ã‚³ã‚¢ã‚’0-100ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

è©•ä¾¡åŸºæº–:
- å…·ä½“çš„ãªæ”¹å–„ææ¡ˆ +15ç‚¹
- å”åŠ›çš„ãªå§¿å‹¢ +10ç‚¹
- æ„Ÿè¬ã®è¡¨ç¾ +10ç‚¹
- å€‹äººæ”»æ’ƒ -20ç‚¹
- å¦å®šçš„è¡¨ç¾ -15ç‚¹
- éå»ºè¨­çš„ãªæ‰¹åˆ¤ -10ç‚¹

æŠ•ç¨¿å†…å®¹:
{content}

ã‚¹ã‚³ã‚¢ï¼ˆ0-100ã®æ•°å€¤ã®ã¿ï¼‰:
"""

    response = ollama.generate(
        model='llama-3.2-8b',
        prompt=prompt,
        temperature=0.3  # ä¸€è²«æ€§é‡è¦–
    )

    # LLMã‹ã‚‰ã‚¹ã‚³ã‚¢æŠ½å‡º
    score = int(re.search(r'\d+', response['response']).group())
    return max(0, min(100, score))
```

#### âœ… é‡å¤§åº¦ã®æ®µéšçš„åˆ¤å®š

**MockLLMå®Ÿè£…**:
```typescript
private calculateSeverity(
  violations: LLMViolation[],
  constructiveScore: number
): 'none' | 'low' | 'medium' | 'high' | 'critical' {
  if (violations.length === 0 && constructiveScore >= 60) {
    return 'none';
  }

  if (violations.length === 0 && constructiveScore >= 40) {
    return 'low';
  }

  const hasCritical = violations.some(v => v.severity === 'critical');
  if (hasCritical) return 'critical';

  const hasHigh = violations.some(v => v.severity === 'high');
  if (hasHigh || violations.length >= 3) return 'high';

  const hasMedium = violations.some(v => v.severity === 'medium');
  if (hasMedium || violations.length >= 2) return 'medium';

  return 'low';
}
```

**å­¦ã³**:
- é•åã®æœ‰ç„¡ã¨å»ºè¨­æ€§ã‚¹ã‚³ã‚¢ã‚’ç·åˆåˆ¤å®š
- é•åæ•°ã«ã‚ˆã‚‹é‡å¤§åº¦ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- æœ€ã‚‚é‡ã„é•åã«å¼•ããšã‚‰ã‚Œã‚‹è¨­è¨ˆ

**åŒ»ç™‚ãƒãƒ¼ãƒ ã§ã®æ´»ç”¨**:
```python
# å®Œå…¨ã«MockLLMã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…
# ä¸€è²«æ€§ã‚’æœ€å„ªå…ˆ
def calculate_severity(
    violations: List[ViolationDetail],
    constructive_score: int
) -> str:
    """
    VoiceDrive MockLLMã¨å®Œå…¨ä¸€è‡´ã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯
    """
    if len(violations) == 0 and constructive_score >= 60:
        return 'none'

    if len(violations) == 0 and constructive_score >= 40:
        return 'low'

    has_critical = any(v.severity == 'critical' for v in violations)
    if has_critical:
        return 'critical'

    has_high = any(v.severity == 'high' for v in violations)
    if has_high or len(violations) >= 3:
        return 'high'

    has_medium = any(v.severity == 'medium' for v in violations)
    if has_medium or len(violations) >= 2:
        return 'medium'

    return 'low'
```

#### âœ… ä¿®æ­£ææ¡ˆã®å…·ä½“æ€§

**MockLLMå®Ÿè£…**:
```typescript
private generateSuggestedEdits(content: string, violations: LLMViolation[]): string[] {
  const replacements: Record<string, string> = {
    'ãƒã‚«': 'æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚‹',
    'é¦¬é¹¿': 'æ¤œè¨ãŒå¿…è¦',
    'ã‚¢ãƒ›': 'å†è€ƒãŒå¿…è¦',
    'ç„¡èƒ½': 'èƒ½åŠ›å‘ä¸Šã®æ©Ÿä¼šãŒã‚ã‚‹',
    'å½¹ç«‹ãŸãš': 'ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—ãŒæœŸå¾…ã•ã‚Œã‚‹',
    'ä½¿ãˆãªã„': 'æ”¹å–„ãŒå¿…è¦',
    'ãƒ€ãƒ¡äººé–“': 'æˆé•·ã®ä½™åœ°ãŒã‚ã‚‹',
    'ã‚¯ã‚º': 'æ”¹å–„ãŒå¿…è¦ãªç‚¹ãŒã‚ã‚‹'
  };

  violations.forEach(violation => {
    if (violation.extractedText) {
      const replacement = replacements[violation.extractedText];
      if (replacement) {
        const newContent = content.replace(violation.extractedText, replacement);
        if (!suggestions.includes(newContent)) {
          suggestions.push(newContent);
        }
      }
    }
  });

  return suggestions.slice(0, 3);  // æœ€å¤§3ã¤ã®ææ¡ˆ
}
```

**å­¦ã³**:
- å…·ä½“çš„ãªç½®ãæ›ãˆè¡¨ç¾ã®è¾æ›¸
- æ”»æ’ƒçš„è¡¨ç¾ã‚’å»ºè¨­çš„è¡¨ç¾ã«å¤‰æ›
- æœ€å¤§3ã¤ã®ææ¡ˆï¼ˆéåº¦ã«ãªã‚‰ãªã„ï¼‰

**åŒ»ç™‚ãƒãƒ¼ãƒ ã§ã®æ´»ç”¨**:
```python
# Llama 3.2 8Bã§ã®é«˜åº¦ãªä¿®æ­£ææ¡ˆ
def generate_suggested_edits_llm(
    content: str,
    violations: List[ViolationDetail]
) -> List[str]:
    """
    LLMã‚’ä½¿ã£ãŸæ–‡è„ˆã‚’è€ƒæ…®ã—ãŸä¿®æ­£ææ¡ˆ
    MockLLMã®è¾æ›¸ãƒ™ãƒ¼ã‚¹ã‚ˆã‚Šè‡ªç„¶
    """
    prompt = f"""
ä»¥ä¸‹ã®æŠ•ç¨¿ã«ã¯å•é¡Œã®ã‚ã‚‹è¡¨ç¾ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
ã‚ˆã‚Šå»ºè¨­çš„ã§å°Šé‡çš„ãªè¡¨ç¾ã«æ›¸ãæ›ãˆã¦ãã ã•ã„ã€‚

å…ƒã®æŠ•ç¨¿:
{content}

æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:
{', '.join([v.description for v in violations])}

ä¿®æ­£ææ¡ˆï¼ˆæœ€å¤§3ã¤ã€å„è¡Œã«1ã¤ãšã¤ï¼‰:
"""

    response = ollama.generate(
        model='llama-3.2-8b',
        prompt=prompt,
        temperature=0.7  # å‰µé€ æ€§é‡è¦–
    )

    suggestions = response['response'].strip().split('\n')
    return [s.strip() for s in suggestions if s.strip()][:3]
```

#### âœ… ãƒªã‚¢ãƒ«ãªå‡¦ç†æ™‚é–“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

**MockLLMå®Ÿè£…**:
```typescript
private async simulateProcessingTime(): Promise<void> {
  const delay = 300 + Math.random() * 500;  // 300-800ms
  return new Promise(resolve => setTimeout(resolve, delay));
}
```

**å­¦ã³**:
- å®ŸLLMã®å‡¦ç†æ™‚é–“ï¼ˆ300-800msï¼‰ã‚’æ­£ç¢ºã«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
- VoiceDriveãƒãƒ¼ãƒ ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆ3ç§’ï¼‰ã®æ ¹æ‹ 

**åŒ»ç™‚ãƒãƒ¼ãƒ ã®ç›®æ¨™**:
```python
# ç›®æ¨™: MockLLMã‚ˆã‚Šé«˜é€Ÿ
# å¹³å‡1.5ç§’ï¼ˆMockLLMã®å¹³å‡550msã®ç´„2.7å€ï¼‰
# ã“ã‚Œã¯ååˆ†è¨±å®¹ç¯„å›²ï¼ˆVoiceDriveè¦æ±‚ã¯2ç§’ä»¥å†…ï¼‰

# å®Ÿæ¸¬å€¤ã®æœŸå¾…å€¤
EXPECTED_PROCESSING_TIMES = {
    'cache_hit': 50,        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ™‚: 50ms
    'simple_content': 800,  # å˜ç´”ãªå†…å®¹: 800ms
    'complex_content': 1500, # è¤‡é›‘ãªå†…å®¹: 1.5ç§’
    'edge_case': 2500       # ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹: 2.5ç§’ï¼ˆP95ï¼‰
}
```

### 1.2 MockLLMã¨ã®ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

#### å›å¸°ãƒ†ã‚¹ãƒˆ

```python
# tests/regression_test_mock_vs_real.py

import pytest
from medical_llm_api import ModerationService
from voicedrive_mock import MockLLMAPIServer

@pytest.fixture
def mock_llm():
    return MockLLMAPIServer.getInstance()

@pytest.fixture
def real_llm():
    return ModerationService()

def test_consistency_with_mock(mock_llm, real_llm):
    """
    MockLLMã¨å®ŸLLMã®ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ
    230ä»¶ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å…¨ã¦ã§90%ä»¥ä¸Šã®ä¸€è‡´ç‡ã‚’ç›®æŒ‡ã™
    """
    test_cases = load_voicedrive_test_cases()  # 230ä»¶

    consistency_scores = []

    for case in test_cases:
        mock_result = mock_llm.moderate(case.content)
        real_result = real_llm.moderate(case.content)

        # ä¸€è²«æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
        consistency = calculate_consistency(mock_result, real_result)
        consistency_scores.append(consistency)

        # é‡è¦ãªé …ç›®ã®ä¸€è‡´ã‚’ç¢ºèª
        assert mock_result['allowed'] == real_result['allowed'], \
            f"allowedåˆ¤å®šãŒä¸ä¸€è‡´: {case.content}"

        assert abs(mock_result['confidence'] - real_result['confidence']) < 15, \
            f"ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ãŒ15%ä»¥ä¸Šä¹–é›¢: {case.content}"

    # å…¨ä½“ã®ä¸€è²«æ€§
    avg_consistency = sum(consistency_scores) / len(consistency_scores)
    assert avg_consistency >= 0.90, \
        f"ä¸€è²«æ€§ã‚¹ã‚³ã‚¢ãŒ90%æœªæº€: {avg_consistency:.2%}"

def calculate_consistency(mock_result, real_result) -> float:
    """
    2ã¤ã®çµæœã®ä¸€è²«æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆ0.0-1.0ï¼‰
    """
    score = 0.0

    # allowedåˆ¤å®šãŒä¸€è‡´ï¼ˆ30ç‚¹ï¼‰
    if mock_result['allowed'] == real_result['allowed']:
        score += 0.3

    # severityåˆ¤å®šãŒä¸€è‡´ï¼ˆ25ç‚¹ï¼‰
    if mock_result['severity'] == real_result['severity']:
        score += 0.25

    # confidenceå·®ãŒ10%ä»¥å†…ï¼ˆ25ç‚¹ï¼‰
    confidence_diff = abs(mock_result['confidence'] - real_result['confidence'])
    if confidence_diff <= 10:
        score += 0.25
    elif confidence_diff <= 20:
        score += 0.15

    # violationsæ•°ãŒä¸€è‡´ï¼ˆ20ç‚¹ï¼‰
    mock_violations = len(mock_result['violations'])
    real_violations = len(real_result['violations'])
    if mock_violations == real_violations:
        score += 0.20
    elif abs(mock_violations - real_violations) <= 1:
        score += 0.10

    return score
```

---

## åŒ»ç™‚ãƒãƒ¼ãƒ å®Ÿè£…ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### 2.1 å…¨ä½“æ§‹æˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FastAPI Application                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  ğŸ”Œ API Endpoints                           â”‚
â”‚  â”œâ”€ POST /api/moderate                      â”‚
â”‚  â”œâ”€ POST /api/moderate/batch                â”‚
â”‚  â”œâ”€ GET  /api/health                        â”‚
â”‚  â””â”€ GET  /api/metrics                       â”‚
â”‚                                             â”‚
â”‚  ğŸ§  Moderation Service                      â”‚
â”‚  â”œâ”€ LLM Engine (Ollama + Llama 3.2 8B)     â”‚
â”‚  â”œâ”€ Prompt Templates                        â”‚
â”‚  â”œâ”€ Violation Detector                     â”‚
â”‚  â”œâ”€ Confidence Calculator                  â”‚
â”‚  â””â”€ Suggestion Generator                   â”‚
â”‚                                             â”‚
â”‚  ğŸ’¾ Cache Layer (Redis)                     â”‚
â”‚  â”œâ”€ Response Cache (5min)                  â”‚
â”‚  â”œâ”€ Pattern Cache                          â”‚
â”‚  â””â”€ Statistics Cache                       â”‚
â”‚                                             â”‚
â”‚  ğŸ“Š Metrics & Logging                       â”‚
â”‚  â”œâ”€ Prometheus Metrics                     â”‚
â”‚  â”œâ”€ CloudWatch Logs                        â”‚
â”‚  â””â”€ Performance Monitoring                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

```
medical-llm-api/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                    # FastAPI app
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ moderate.py            # POST /api/moderate
â”‚   â”‚   â”‚   â”œâ”€â”€ batch.py               # POST /api/moderate/batch
â”‚   â”‚   â”‚   â”œâ”€â”€ health.py              # GET /api/health
â”‚   â”‚   â”‚   â””â”€â”€ metrics.py             # GET /api/metrics
â”‚   â”‚   â””â”€â”€ types.py                   # Pydantic models
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ moderation_service.py      # ãƒ¡ã‚¤ãƒ³ã‚µãƒ¼ãƒ“ã‚¹
â”‚   â”‚   â”œâ”€â”€ llm_engine.py              # Ollamaçµ±åˆ
â”‚   â”‚   â”œâ”€â”€ violation_detector.py     # é•åæ¤œå‡º
â”‚   â”‚   â”œâ”€â”€ confidence_calculator.py  # ä¿¡é ¼åº¦è¨ˆç®—
â”‚   â”‚   â””â”€â”€ suggestion_generator.py   # ä¿®æ­£ææ¡ˆç”Ÿæˆ
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ violation_detection.py    # é•åæ¤œå‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
â”‚   â”‚   â”œâ”€â”€ constructive_score.py     # å»ºè¨­æ€§ã‚¹ã‚³ã‚¢
â”‚   â”‚   â””â”€â”€ suggestion_generation.py  # ä¿®æ­£ææ¡ˆ
â”‚   â”‚
â”‚   â”œâ”€â”€ cache/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ redis_cache.py            # Redisã‚­ãƒ£ãƒƒã‚·ãƒ¥
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ text_processor.py         # ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†
â”‚       â””â”€â”€ medical_patterns.py       # åŒ»ç™‚è¡¨ç¾è¾æ›¸
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                          # å˜ä½“ãƒ†ã‚¹ãƒˆ
â”‚   â”œâ”€â”€ integration/                   # çµ±åˆãƒ†ã‚¹ãƒˆ
â”‚   â””â”€â”€ regression/                    # MockLLMä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ patterns/
â”‚   â”‚   â”œâ”€â”€ voicedrive_mock_patterns.json  # MockLLMãƒ‘ã‚¿ãƒ¼ãƒ³
â”‚   â”‚   â””â”€â”€ medical_expressions.json       # åŒ»ç™‚è¡¨ç¾1000ä»¶
â”‚   â””â”€â”€ training/
â”‚       â””â”€â”€ few_shot_samples.json          # Few-shot 100ä»¶
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

## Llama 3.2 8Bãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

### 3.1 é•åæ¤œå‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

```python
# src/prompts/violation_detection.py

VIOLATION_DETECTION_PROMPT = """
ã‚ãªãŸã¯åŒ»ç™‚æ³•äººã®SNSæŠ•ç¨¿ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
è·å“¡ã®æŠ•ç¨¿å†…å®¹ã‚’åˆ†æã—ã€11ç¨®é¡ã®é•åã‚¿ã‚¤ãƒ—ã‚’æ¤œå‡ºã—ã¦ãã ã•ã„ã€‚

åŒ»ç™‚ç¾å ´ç‰¹æœ‰ã®è¡¨ç¾ã®è€ƒæ…®:
- ã€Œã“ã®æ‰‹æŠ€ã¯å³ã—ã„ã€ã€Œå¤œå‹¤ã¯éé…·ã€ç­‰ã¯æ¥­å‹™ã®é›£æ˜“åº¦ã‚„åŠ´åƒç’°å¢ƒã®è¨˜è¿°ã¨ã—ã¦æ­£å¸¸ã¨åˆ¤å®š
- ã€Œâ—‹â—‹åŒ»å¸«ã®æŒ‡ç¤ºãŒä¸æ˜ç¢ºã€ç­‰ã€å€‹äººåã‚’å«ã‚€ãŒå»ºè¨­çš„ãªæŒ‡æ‘˜ã¯è­¦å‘Šãƒ¬ãƒ™ãƒ«

æŠ•ç¨¿å†…å®¹:
{content}

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:
- æŠ•ç¨¿ã‚¿ã‚¤ãƒ—: {post_type}
- æŠ•ç¨¿è€…ãƒ¬ãƒ™ãƒ«: {author_level}
- éƒ¨ç½²: {department}

11ç¨®é¡ã®é•åã‚¿ã‚¤ãƒ—:
1. personal_attackï¼ˆå€‹äººæ”»æ’ƒï¼‰: ç‰¹å®šå€‹äººã¸ã®æ”»æ’ƒçš„è¡¨ç¾
2. defamationï¼ˆèª¹è¬—ä¸­å‚·ï¼‰: æ ¹æ‹ ã®ãªã„æ‚ªè©•
3. harassmentï¼ˆãƒãƒ©ã‚¹ãƒ¡ãƒ³ãƒˆï¼‰: ãƒ‘ãƒ¯ãƒãƒ©ãƒ»ã‚»ã‚¯ãƒãƒ©ç­‰
4. discriminationï¼ˆå·®åˆ¥çš„è¡¨ç¾ï¼‰: æ€§åˆ¥ãƒ»å¹´é½¢ãƒ»å›½ç±ç­‰ã«ã‚ˆã‚‹å·®åˆ¥
5. privacy_violationï¼ˆãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¾µå®³ï¼‰: å€‹äººæƒ…å ±ã®ä¸é©åˆ‡ãªè¨˜è¼‰
6. inappropriate_contentï¼ˆä¸é©åˆ‡ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼‰: è·å ´ã«ä¸é©åˆ‡ãªå†…å®¹
7. threateningï¼ˆè„…è¿«çš„è¡¨ç¾ï¼‰: è„…è¿«ãƒ»å¨åš‡
8. hate_speechï¼ˆãƒ˜ã‚¤ãƒˆã‚¹ãƒ”ãƒ¼ãƒï¼‰: æ†æ‚ªãƒ»æ•µæ„ã®è¡¨ç¾
9. misinformationï¼ˆèª¤æƒ…å ±ï¼‰: è™šå½æƒ…å ±ãƒ»ãƒ‡ãƒ
10. spamï¼ˆã‚¹ãƒ‘ãƒ ï¼‰: å®£ä¼ãƒ»åºƒå‘Š
11. otherï¼ˆãã®ä»–ï¼‰: ä¸Šè¨˜ã«è©²å½“ã—ãªã„å•é¡Œ

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼ˆJSONä»¥å¤–ã®æ–‡ç« ã¯ä¸è¦ï¼‰:
{{
  "violations": [
    {{
      "type": "personal_attack",
      "severity": "high",
      "description": "ã€Œãƒã‚«ã€ã¨ã„ã†å€‹äººæ”»æ’ƒçš„ãªè¡¨ç¾",
      "extractedText": "ãƒã‚«",
      "startIndex": 10,
      "endIndex": 12,
      "confidence": 92
    }}
  ],
  "constructiveScore": 25,
  "reasoning": "å€‹äººæ”»æ’ƒçš„ãªè¡¨ç¾ãŒå«ã¾ã‚Œã¦ã„ã¾ã™"
}}
"""

def create_violation_detection_prompt(
    content: str,
    post_type: str = 'improvement',
    author_level: int = 3,
    department: str = 'çœ‹è­·éƒ¨'
) -> str:
    """
    é•åæ¤œå‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
    """
    return VIOLATION_DETECTION_PROMPT.format(
        content=content,
        post_type=post_type,
        author_level=author_level,
        department=department
    )
```

### 3.2 Few-shot Learning

```python
# data/training/few_shot_samples.json

FEW_SHOT_SAMPLES = [
    {
        "input": "å¤œå‹¤ã®ã‚·ãƒ•ãƒˆèª¿æ•´æ–¹æ³•ã‚’æ”¹å–„ã™ã¹ãã§ã™ã€‚ç¾çŠ¶ã¯è² æ‹…ãŒå¤§ãã„ã§ã™ã€‚",
        "output": {
            "violations": [],
            "constructiveScore": 75,
            "reasoning": "å»ºè¨­çš„ãªæ”¹å–„ææ¡ˆã§ã™ã€‚æ¥­å‹™è² æ‹…ã®æŒ‡æ‘˜ã¯æ­£å¸¸ãªè¡¨ç¾ã§ã™ã€‚"
        }
    },
    {
        "input": "â—‹â—‹ã•ã‚“ã¯ãƒã‚«ã ã‹ã‚‰ä»•äº‹ãŒã§ããªã„ã€‚",
        "output": {
            "violations": [
                {
                    "type": "personal_attack",
                    "severity": "high",
                    "description": "ã€Œãƒã‚«ã€ã¨ã„ã†å€‹äººæ”»æ’ƒçš„ãªè¡¨ç¾",
                    "extractedText": "ãƒã‚«",
                    "startIndex": 5,
                    "endIndex": 7,
                    "confidence": 95
                }
            ],
            "constructiveScore": 10,
            "reasoning": "ç‰¹å®šå€‹äººã¸ã®æ”»æ’ƒçš„ãªè¡¨ç¾ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚"
        }
    },
    # ... 100ä»¶ã®ã‚µãƒ³ãƒ—ãƒ«
]

# Few-shot Learningã‚’ä½¿ã£ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¼·åŒ–
def create_few_shot_prompt(content: str, num_examples: int = 5) -> str:
    """
    Few-shot ã‚µãƒ³ãƒ—ãƒ«ã‚’å«ã‚€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
    """
    examples = random.sample(FEW_SHOT_SAMPLES, num_examples)

    examples_text = "\n\n".join([
        f"ä¾‹{i+1}:\nå…¥åŠ›: {ex['input']}\nå‡ºåŠ›: {json.dumps(ex['output'], ensure_ascii=False)}"
        for i, ex in enumerate(examples)
    ])

    return f"""
{examples_text}

å®Ÿéš›ã®æŠ•ç¨¿ã‚’åˆ†æã—ã¦ãã ã•ã„:
å…¥åŠ›: {content}
å‡ºåŠ›:
"""
```

---

## é•åæ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè£…

### 4.1 LLMã‚¨ãƒ³ã‚¸ãƒ³

```python
# src/services/llm_engine.py

import ollama
import json
from typing import Dict, Any

class LLMEngine:
    def __init__(self):
        self.model = 'llama-3.2-8b'
        self.default_temperature = 0.3  # ä¸€è²«æ€§é‡è¦–

    def generate(
        self,
        prompt: str,
        temperature: float = None,
        max_tokens: int = 1000
    ) -> Dict[str, Any]:
        """
        Llama 3.2 8Bã§æ¨è«–å®Ÿè¡Œ
        """
        response = ollama.generate(
            model=self.model,
            prompt=prompt,
            options={
                'temperature': temperature or self.default_temperature,
                'num_predict': max_tokens,
                'top_p': 0.9,
                'top_k': 40
            }
        )

        return response

    def extract_json(self, response_text: str) -> Dict[str, Any]:
        """
        LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰JSONæŠ½å‡º
        """
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‰Šé™¤
        text = response_text.strip()
        if text.startswith('```json'):
            text = text[7:]
        if text.startswith('```'):
            text = text[3:]
        if text.endswith('```'):
            text = text[:-3]

        # JSONéƒ¨åˆ†ã®ã¿æŠ½å‡º
        start = text.find('{')
        end = text.rfind('}') + 1
        json_text = text[start:end]

        return json.loads(json_text)
```

### 4.2 é•åæ¤œå‡ºã‚µãƒ¼ãƒ“ã‚¹

```python
# src/services/violation_detector.py

from src.services.llm_engine import LLMEngine
from src.prompts.violation_detection import create_violation_detection_prompt
from src.api.types import ViolationDetail
from typing import List, Tuple

class ViolationDetector:
    def __init__(self):
        self.llm = LLMEngine()

    def detect(
        self,
        content: str,
        post_type: str = 'improvement',
        author_level: int = 3,
        department: str = 'çœ‹è­·éƒ¨'
    ) -> Tuple[List[ViolationDetail], int, str]:
        """
        é•åæ¤œå‡ºã‚’å®Ÿè¡Œ

        Returns:
            violations: æ¤œå‡ºã•ã‚ŒãŸé•åãƒªã‚¹ãƒˆ
            constructive_score: å»ºè¨­æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰
            reasoning: åˆ¤å®šç†ç”±
        """
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        prompt = create_violation_detection_prompt(
            content, post_type, author_level, department
        )

        # LLMæ¨è«–
        response = self.llm.generate(prompt)
        result = self.llm.extract_json(response['response'])

        # é•åãƒªã‚¹ãƒˆæ§‹ç¯‰
        violations = [
            ViolationDetail(**v)
            for v in result.get('violations', [])
        ]

        # å»ºè¨­æ€§ã‚¹ã‚³ã‚¢
        constructive_score = result.get('constructiveScore', 50)

        # åˆ¤å®šç†ç”±
        reasoning = result.get('reasoning', '')

        return violations, constructive_score, reasoning
```

---

## ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—

### 5.1 VoiceDrive MockLLMæº–æ‹ ã®å®Ÿè£…

```python
# src/services/confidence_calculator.py

from typing import List
from src.api.types import ViolationDetail

class ConfidenceCalculator:
    """
    VoiceDrive MockLLMã¨å®Œå…¨ä¸€è‡´ã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯
    """

    def calculate(
        self,
        violations: List[ViolationDetail],
        content: str
    ) -> int:
        """
        ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆ0-100ï¼‰

        MockLLMã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯:
        - é•åãªã—: ãƒ†ã‚­ã‚¹ãƒˆé•·ã«å¿œã˜ã¦70-95%
        - é•åã‚ã‚Š: é•åã®å¹³å‡ä¿¡é ¼åº¦
        """
        if len(violations) == 0:
            # é•åãªã—ã®å ´åˆã€ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã„ã»ã©ä¿¡é ¼åº¦ãŒé«˜ã„
            base_confidence = 70
            length_bonus = min(25, (len(content) // 50) * 5)
            return base_confidence + length_bonus

        # é•åã‚ã‚Šã®å ´åˆã€é•åã®å¹³å‡ä¿¡é ¼åº¦
        avg_confidence = sum(v.confidence for v in violations) / len(violations)
        return round(avg_confidence)

    def calculate_pattern_confidence(self, matched_text: str) -> int:
        """
        ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒã®ä¿¡é ¼åº¦ã‚’è¨ˆç®—

        MockLLMã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯:
        - ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦75%
        - ãƒãƒƒãƒæ–‡å­—åˆ—ãŒé•·ã„ã»ã© +20%ã¾ã§
        """
        base_confidence = 75
        length_bonus = min(20, len(matched_text) * 2)
        return min(95, base_confidence + length_bonus)
```

---

## ä¿®æ­£ææ¡ˆç”Ÿæˆ

### 6.1 LLMãƒ™ãƒ¼ã‚¹ã®é«˜åº¦ãªææ¡ˆ

```python
# src/services/suggestion_generator.py

from src.services.llm_engine import LLMEngine
from src.api.types import ViolationDetail
from typing import List

class SuggestionGenerator:
    def __init__(self):
        self.llm = LLMEngine()

    def generate(
        self,
        content: str,
        violations: List[ViolationDetail]
    ) -> List[str]:
        """
        ä¿®æ­£ææ¡ˆã‚’ç”Ÿæˆï¼ˆæœ€å¤§3ã¤ï¼‰

        MockLLMã®è¾æ›¸ãƒ™ãƒ¼ã‚¹ã‚ˆã‚Šæ–‡è„ˆã‚’è€ƒæ…®ã—ãŸè‡ªç„¶ãªææ¡ˆ
        """
        if len(violations) == 0:
            return []

        # é•åå†…å®¹ã‚’ã¾ã¨ã‚ã‚‹
        violation_descriptions = [
            f"- {v.description}ï¼ˆã€Œ{v.extractedText}ã€ï¼‰"
            for v in violations
            if v.extractedText
        ]

        prompt = f"""
ä»¥ä¸‹ã®æŠ•ç¨¿ã«ã¯å•é¡Œã®ã‚ã‚‹è¡¨ç¾ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
ã‚ˆã‚Šå»ºè¨­çš„ã§å°Šé‡çš„ãªè¡¨ç¾ã«æ›¸ãæ›ãˆãŸä¿®æ­£æ¡ˆã‚’3ã¤ææ¡ˆã—ã¦ãã ã•ã„ã€‚

å…ƒã®æŠ•ç¨¿:
{content}

æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:
{chr(10).join(violation_descriptions)}

ä¿®æ­£ææ¡ˆã®ãƒ«ãƒ¼ãƒ«:
1. å…ƒã®æŠ•ç¨¿ã®æ„å›³ã‚’ä¿æŒã™ã‚‹
2. æ”»æ’ƒçš„è¡¨ç¾ã‚’å»ºè¨­çš„è¡¨ç¾ã«ç½®ãæ›ãˆã‚‹
3. å€‹äººåã¯ã€Œæ‹…å½“è€…ã€ã€Œé–¢ä¿‚è€…ã€ç­‰ã«ä¸€èˆ¬åŒ–
4. å…·ä½“çš„ãªæ”¹å–„ææ¡ˆã‚’å«ã‚ã‚‹

ä¿®æ­£ææ¡ˆï¼ˆæœ€å¤§3ã¤ã€å„è¡Œã«1ã¤ãšã¤ã€ç•ªå·ä¸è¦ï¼‰:
"""

        response = self.llm.generate(
            prompt,
            temperature=0.7  # å‰µé€ æ€§é‡è¦–
        )

        # ææ¡ˆã‚’æŠ½å‡º
        suggestions = [
            line.strip()
            for line in response['response'].strip().split('\n')
            if line.strip() and not line.strip().startswith('#')
        ]

        return suggestions[:3]  # æœ€å¤§3ã¤
```

---

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 7.1 ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥

```python
# src/cache/redis_cache.py

import redis
import hashlib
import json
from typing import Optional, Dict, Any

class ResponseCache:
    def __init__(self):
        self.redis_client = redis.Redis(
            host='localhost',
            port=6379,
            db=0,
            decode_responses=True
        )
        self.ttl = 300  # 5åˆ†é–“ï¼ˆVoiceDriveä»•æ§˜ï¼‰

    def get_cache_key(self, content: str) -> str:
        """
        ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã¨ã™ã‚‹
        """
        return f"llm:moderation:{hashlib.sha256(content.encode()).hexdigest()}"

    def get(self, content: str) -> Optional[Dict[str, Any]]:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
        """
        key = self.get_cache_key(content)
        cached = self.redis_client.get(key)

        if cached:
            return json.loads(cached)
        return None

    def set(self, content: str, result: Dict[str, Any]) -> None:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ï¼ˆ5åˆ†é–“ï¼‰
        """
        key = self.get_cache_key(content)
        self.redis_client.setex(
            key,
            self.ttl,
            json.dumps(result, ensure_ascii=False)
        )

    def clear_old_entries(self) -> None:
        """
        å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤ï¼ˆè‡ªå‹•å®Ÿè¡Œï¼‰
        """
        # Redisã®è‡ªå‹•æœŸé™åˆ‡ã‚Œã«ä»»ã›ã‚‹
        pass
```

### 7.2 ãƒãƒƒãƒå‡¦ç†

```python
# src/services/batch_moderation_service.py

from typing import List, Dict, Any
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from src.services.moderation_service import ModerationService

class BatchModerationService:
    def __init__(self):
        self.moderation_service = ModerationService()
        self.max_workers = 5  # æœ€å¤§5ä»¶ã®ä¸¦åˆ—å‡¦ç†

    def moderate_batch(
        self,
        requests: List[Dict[str, Any]],
        max_batch_size: int = 10
    ) -> Dict[str, Any]:
        """
        ãƒãƒƒãƒå‡¦ç†ï¼ˆæœ€å¤§10ä»¶ï¼‰

        ä¸¦åˆ—åŒ–ã«ã‚ˆã‚Šå‡¦ç†æ™‚é–“ã‚’60-70%ã«çŸ­ç¸®
        """
        if len(requests) > max_batch_size:
            raise ValueError(f"ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯{max_batch_size}ä»¶ä»¥ä¸‹ã«ã—ã¦ãã ã•ã„")

        start_time = time.time()
        results = []

        # ä¸¦åˆ—å‡¦ç†
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_req = {
                executor.submit(
                    self.moderation_service.moderate,
                    req['content'],
                    req.get('context'),
                    req.get('options')
                ): req['postId']
                for req in requests
            }

            for future in as_completed(future_to_req):
                post_id = future_to_req[future]
                try:
                    result = future.result()
                    results.append({
                        'postId': post_id,
                        **result
                    })
                except Exception as e:
                    results.append({
                        'postId': post_id,
                        'error': str(e)
                    })

        total_time = (time.time() - start_time) * 1000  # ãƒŸãƒªç§’

        return {
            'results': results,
            'totalProcessingTime': total_time,
            'metadata': {
                'batchSize': len(requests),
                'successCount': len([r for r in results if 'error' not in r]),
                'failureCount': len([r for r in results if 'error' in r])
            }
        }
```

---

## ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### 8.1 MockLLMä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ

```python
# tests/regression/test_mock_consistency.py

import pytest
from src.services.moderation_service import ModerationService

# VoiceDriveã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹230ä»¶ã‚’ãƒ­ãƒ¼ãƒ‰
VOICEDRIVE_TEST_CASES = load_test_cases('voicedrive_230_cases.json')

@pytest.mark.parametrize("test_case", VOICEDRIVE_TEST_CASES)
def test_consistency_with_mock(test_case):
    """
    å„ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã§MockLLMã¨ã®ä¸€è²«æ€§ã‚’ç¢ºèª
    """
    service = ModerationService()

    # å®ŸLLMã§åˆ¤å®š
    result = service.moderate(test_case.content)

    # MockLLMã®æœŸå¾…å€¤ã¨æ¯”è¼ƒ
    mock_expected = test_case.mock_result

    # é‡è¦é …ç›®ã®ä¸€è‡´ç¢ºèª
    assert result['allowed'] == mock_expected['allowed'], \
        f"allowedåˆ¤å®šãŒä¸ä¸€è‡´"

    # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã®è¨±å®¹èª¤å·®15%
    confidence_diff = abs(result['confidence'] - mock_expected['confidence'])
    assert confidence_diff < 15, \
        f"ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ãŒ15%ä»¥ä¸Šä¹–é›¢: {confidence_diff}%"

    # ä¸€è²«æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
    consistency = calculate_consistency(result, mock_expected)
    assert consistency >= 0.85, \
        f"ä¸€è²«æ€§ã‚¹ã‚³ã‚¢ãŒ85%æœªæº€: {consistency:.2%}"
```

### 8.2 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

```python
# tests/performance/test_response_time.py

import pytest
import time
from src.services.moderation_service import ModerationService

def test_average_response_time():
    """
    å¹³å‡å¿œç­”æ™‚é–“ãŒ1.5ç§’ä»¥å†…
    """
    service = ModerationService()
    test_contents = load_test_contents(100)  # 100ä»¶

    times = []
    for content in test_contents:
        start = time.time()
        service.moderate(content)
        elapsed = (time.time() - start) * 1000  # ãƒŸãƒªç§’
        times.append(elapsed)

    avg_time = sum(times) / len(times)
    assert avg_time < 1500, \
        f"å¹³å‡å¿œç­”æ™‚é–“ãŒ1.5ç§’ã‚’è¶…é: {avg_time:.1f}ms"

def test_p95_response_time():
    """
    P95å¿œç­”æ™‚é–“ãŒ2.5ç§’ä»¥å†…
    """
    service = ModerationService()
    test_contents = load_test_contents(100)

    times = []
    for content in test_contents:
        start = time.time()
        service.moderate(content)
        elapsed = (time.time() - start) * 1000
        times.append(elapsed)

    times.sort()
    p95_time = times[int(len(times) * 0.95)]
    assert p95_time < 2500, \
        f"P95å¿œç­”æ™‚é–“ãŒ2.5ç§’ã‚’è¶…é: {p95_time:.1f}ms"
```

---

## å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### Week 5-6: åŸºç›¤ãƒ»ã‚³ã‚¢æ©Ÿèƒ½

- [ ] FastAPIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ–
- [ ] Ollama + Llama 3.2 8Bã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
- [ ] `/api/moderate` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®Ÿè£…
- [ ] Pydanticå‹å®šç¾©ï¼ˆVoiceDrive TypeScriptå‹ã¨ä¸€è‡´ï¼‰
- [ ] LLMEngineå®Ÿè£…
- [ ] é•åæ¤œå‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆï¼ˆ11ç¨®é¡ï¼‰
- [ ] ViolationDetectorå®Ÿè£…
- [ ] ConfidenceCalculatorå®Ÿè£…ï¼ˆMockLLMæº–æ‹ ï¼‰
- [ ] SuggestionGeneratorå®Ÿè£…
- [ ] åŒ»ç™‚ç¾å ´ç‰¹æœ‰è¡¨ç¾è¾æ›¸ä½œæˆï¼ˆ1000ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
- [ ] Few-shot Learningã‚µãƒ³ãƒ—ãƒ«ä½œæˆï¼ˆ100ä»¶ï¼‰

### Week 7: æœ€é©åŒ–

- [ ] Redisã‚­ãƒ£ãƒƒã‚·ãƒ¥å®Ÿè£…
- [ ] ãƒãƒƒãƒå‡¦ç†APIå®Ÿè£…
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿæ–½
  - [ ] å¹³å‡å¿œç­”æ™‚é–“ < 1.5ç§’
  - [ ] P95å¿œç­”æ™‚é–“ < 2.5ç§’
- [ ] ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡æ¸¬å®šï¼ˆ> 30%ç›®æ¨™ï¼‰

### Week 8: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [ ] API Keyèªè¨¼å®Ÿè£…
- [ ] IPã‚¢ãƒ‰ãƒ¬ã‚¹åˆ¶é™å®Ÿè£…
- [ ] ãƒ‡ãƒ¼ã‚¿å³æ™‚å‰Šé™¤ãƒãƒªã‚·ãƒ¼å®Ÿè£…
- [ ] ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯APIå®Ÿè£…
- [ ] ãƒ¡ãƒˆãƒªã‚¯ã‚¹APIå®Ÿè£…
- [ ] APIä»•æ§˜æ›¸ä½œæˆ
- [ ] é‹ç”¨ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ä½œæˆ

### Week 9-12: ãƒ†ã‚¹ãƒˆ

- [ ] MockLLMä¸€è²«æ€§ãƒ†ã‚¹ãƒˆï¼ˆ230ä»¶ï¼‰
  - [ ] ä¸€è²«æ€§ã‚¹ã‚³ã‚¢ > 90%
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆåˆæ ¼
- [ ] è² è·ãƒ†ã‚¹ãƒˆåˆæ ¼ï¼ˆ24æ™‚é–“ç¨¼åƒï¼‰
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»åˆæ ¼

---

## ğŸ“ ã‚µãƒãƒ¼ãƒˆãƒ»è³ªå•

### VoiceDriveãƒãƒ¼ãƒ ã¸ã®è³ªå•

- MockLLMã®ç‰¹å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ„å›³ç¢ºèª
- ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®è¿½åŠ ä¾é ¼
- ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆã®çµæœå…±æœ‰

### åŒ»ç™‚ãƒãƒ¼ãƒ å†…é€£çµ¡

- LLMã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢: éˆ´æœ¨ä¸€éƒï¼ˆllm@medical-team.localï¼‰
- APIé–‹ç™ºè²¬ä»»è€…: ä½è—¤èŠ±å­ï¼ˆapi@medical-team.localï¼‰

---

**æ–‡æ›¸çµ‚äº†**

*VoiceDriveãƒãƒ¼ãƒ ã®å„ªã‚ŒãŸMockLLMå®Ÿè£…ã‚’å‚è€ƒã«ã€ã‚ˆã‚Šé«˜ç²¾åº¦ãªLlama 3.2 8B APIã‚’å®Ÿè£…ã—ã¾ã™ã€‚*
*ä¸¡ãƒãƒ¼ãƒ ã®å”åŠ›ã«ã‚ˆã‚Šã€å®‰å…¨ã§å»ºè¨­çš„ãªSNSç’°å¢ƒã‚’å®Ÿç¾ã—ã¾ã—ã‚‡ã†ï¼*

**ğŸ¤– åŒ»ç™‚è·å“¡ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãƒãƒ¼ãƒ  - LLMã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°éƒ¨é–€**
**ä½œæˆæ—¥**: 2025å¹´10æœˆ4æ—¥
**å‚ç…§**: VoiceDriveãƒãƒ¼ãƒ  MockLLMAPIServerå®Ÿè£…
